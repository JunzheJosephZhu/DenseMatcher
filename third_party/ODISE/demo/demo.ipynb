{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVlabs/ODISE/blob/master/demo/demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment following if you are running this notebook on Google Colab\n",
    "# !pip uninstall torchtext -y\n",
    "# !pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "# !pip install git+https://@github.com/NVlabs/ODISE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import itertools\n",
    "from contextlib import ExitStack\n",
    "import torch\n",
    "from mask2former.data.datasets.register_ade20k_panoptic import ADE20K_150_CATEGORIES\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from detectron2.config import instantiate\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data.datasets.builtin_meta import COCO_CATEGORIES\n",
    "from detectron2.evaluation import inference_context\n",
    "from detectron2.utils.env import seed_all_rng\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer, random_color\n",
    "\n",
    "from odise import model_zoo\n",
    "from odise.checkpoint import ODISECheckpointer\n",
    "from odise.config import instantiate_odise\n",
    "from odise.data import get_openseg_labels\n",
    "from odise.modeling.wrapper import OpenPanopticInference\n",
    "\n",
    "setup_logger()\n",
    "logger = setup_logger(name=\"odise\")\n",
    "\n",
    "COCO_THING_CLASSES = [\n",
    "    label\n",
    "    for idx, label in enumerate(get_openseg_labels(\"coco_panoptic\", True))\n",
    "    if COCO_CATEGORIES[idx][\"isthing\"] == 1\n",
    "]\n",
    "COCO_THING_COLORS = [c[\"color\"] for c in COCO_CATEGORIES if c[\"isthing\"] == 1]\n",
    "COCO_STUFF_CLASSES = [\n",
    "    label\n",
    "    for idx, label in enumerate(get_openseg_labels(\"coco_panoptic\", True))\n",
    "    if COCO_CATEGORIES[idx][\"isthing\"] == 0\n",
    "]\n",
    "COCO_STUFF_COLORS = [c[\"color\"] for c in COCO_CATEGORIES if c[\"isthing\"] == 0]\n",
    "\n",
    "ADE_THING_CLASSES = [\n",
    "    label\n",
    "    for idx, label in enumerate(get_openseg_labels(\"ade20k_150\", True))\n",
    "    if ADE20K_150_CATEGORIES[idx][\"isthing\"] == 1\n",
    "]\n",
    "ADE_THING_COLORS = [c[\"color\"] for c in ADE20K_150_CATEGORIES if c[\"isthing\"] == 1]\n",
    "ADE_STUFF_CLASSES = [\n",
    "    label\n",
    "    for idx, label in enumerate(get_openseg_labels(\"ade20k_150\", True))\n",
    "    if ADE20K_150_CATEGORIES[idx][\"isthing\"] == 0\n",
    "]\n",
    "ADE_STUFF_COLORS = [c[\"color\"] for c in ADE20K_150_CATEGORIES if c[\"isthing\"] == 0]\n",
    "\n",
    "LVIS_CLASSES = get_openseg_labels(\"lvis_1203\", True)\n",
    "# use beautiful coco colors\n",
    "LVIS_COLORS = list(\n",
    "    itertools.islice(itertools.cycle([c[\"color\"] for c in COCO_CATEGORIES]), len(LVIS_CLASSES))\n",
    ")\n",
    "\n",
    "\n",
    "class VisualizationDemo(object):\n",
    "    def __init__(self, model, metadata, aug, instance_mode=ColorMode.IMAGE):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model (nn.Module):\n",
    "            metadata (MetadataCatalog): image metadata.\n",
    "            instance_mode (ColorMode):\n",
    "            parallel (bool): whether to run the model in different processes from visualization.\n",
    "                Useful since the visualization logic can be slow.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.metadata = metadata\n",
    "        self.aug = aug\n",
    "        self.cpu_device = torch.device(\"cpu\")\n",
    "        self.instance_mode = instance_mode\n",
    "\n",
    "    def predict(self, original_image):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            original_image (np.ndarray): an image of shape (H, W, C) (in BGR order).\n",
    "\n",
    "        Returns:\n",
    "            predictions (dict):\n",
    "                the output of the model for one image only.\n",
    "                See :doc:`/tutorials/models` for details about the format.\n",
    "        \"\"\"\n",
    "        height, width = original_image.shape[:2]\n",
    "        aug_input = T.AugInput(original_image, sem_seg=None)\n",
    "        self.aug(aug_input)\n",
    "        image = aug_input.image\n",
    "        image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "\n",
    "        inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "        predictions = self.model([inputs])[0]\n",
    "        return predictions\n",
    "\n",
    "    def run_on_image(self, image):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image (np.ndarray): an image of shape (H, W, C) (in BGR order).\n",
    "                This is the format used by OpenCV.\n",
    "        Returns:\n",
    "            predictions (dict): the output of the model.\n",
    "            vis_output (VisImage): the visualized image output.\n",
    "        \"\"\"\n",
    "        vis_output = None\n",
    "        predictions = self.predict(image)\n",
    "        visualizer = Visualizer(image, self.metadata, instance_mode=self.instance_mode)\n",
    "        if \"panoptic_seg\" in predictions:\n",
    "            panoptic_seg, segments_info = predictions[\"panoptic_seg\"]\n",
    "            vis_output = visualizer.draw_panoptic_seg(\n",
    "                panoptic_seg.to(self.cpu_device), segments_info\n",
    "            )\n",
    "        else:\n",
    "            if \"sem_seg\" in predictions:\n",
    "                vis_output = visualizer.draw_sem_seg(\n",
    "                    predictions[\"sem_seg\"].argmax(dim=0).to(self.cpu_device)\n",
    "                )\n",
    "            if \"instances\" in predictions:\n",
    "                instances = predictions[\"instances\"].to(self.cpu_device)\n",
    "                vis_output = visualizer.draw_instance_predictions(predictions=instances)\n",
    "\n",
    "        return predictions, vis_output\n",
    "\n",
    "def build_demo_classes_and_metadata(vocab, label_list):\n",
    "    extra_classes = []\n",
    "\n",
    "    if vocab:\n",
    "        for words in vocab.split(\";\"):\n",
    "            extra_classes.append([word.strip() for word in words.split(\",\")])\n",
    "    extra_colors = [random_color(rgb=True, maximum=1) for _ in range(len(extra_classes))]\n",
    "\n",
    "    demo_thing_classes = extra_classes\n",
    "    demo_stuff_classes = []\n",
    "    demo_thing_colors = extra_colors\n",
    "    demo_stuff_colors = []\n",
    "\n",
    "    if \"COCO\" in label_list:\n",
    "        demo_thing_classes += COCO_THING_CLASSES\n",
    "        demo_stuff_classes += COCO_STUFF_CLASSES\n",
    "        demo_thing_colors += COCO_THING_COLORS\n",
    "        demo_stuff_colors += COCO_STUFF_COLORS\n",
    "    if \"ADE\" in label_list:\n",
    "        demo_thing_classes += ADE_THING_CLASSES\n",
    "        demo_stuff_classes += ADE_STUFF_CLASSES\n",
    "        demo_thing_colors += ADE_THING_COLORS\n",
    "        demo_stuff_colors += ADE_STUFF_COLORS\n",
    "    if \"LVIS\" in label_list:\n",
    "        demo_thing_classes += LVIS_CLASSES\n",
    "        demo_thing_colors += LVIS_COLORS\n",
    "\n",
    "    MetadataCatalog.pop(\"odise_demo_metadata\", None)\n",
    "    demo_metadata = MetadataCatalog.get(\"odise_demo_metadata\")\n",
    "    demo_metadata.thing_classes = [c[0] for c in demo_thing_classes]\n",
    "    demo_metadata.stuff_classes = [\n",
    "        *demo_metadata.thing_classes,\n",
    "        *[c[0] for c in demo_stuff_classes],\n",
    "    ]\n",
    "    demo_metadata.thing_colors = demo_thing_colors\n",
    "    demo_metadata.stuff_colors = demo_thing_colors + demo_stuff_colors\n",
    "    demo_metadata.stuff_dataset_id_to_contiguous_id = {\n",
    "        idx: idx for idx in range(len(demo_metadata.stuff_classes))\n",
    "    }\n",
    "    demo_metadata.thing_dataset_id_to_contiguous_id = {\n",
    "        idx: idx for idx in range(len(demo_metadata.thing_classes))\n",
    "    }\n",
    "\n",
    "    demo_classes = demo_thing_classes + demo_stuff_classes\n",
    "\n",
    "    return demo_classes, demo_metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = model_zoo.get_config(\"Panoptic/odise_label_coco_50e.py\", trained=True)\n",
    "\n",
    "cfg.model.overlap_threshold = 0\n",
    "seed_all_rng(42)\n",
    "\n",
    "dataset_cfg = cfg.dataloader.test\n",
    "wrapper_cfg = cfg.dataloader.wrapper\n",
    "\n",
    "aug = instantiate(dataset_cfg.mapper).augmentations\n",
    "\n",
    "model = instantiate_odise(cfg.model)\n",
    "model.to(cfg.train.device)\n",
    "ODISECheckpointer(model).load(cfg.train.init_checkpoint)\n",
    "\"finished loading model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image, vocab, label_list):\n",
    "\n",
    "    demo_classes, demo_metadata = build_demo_classes_and_metadata(vocab, label_list)\n",
    "    with ExitStack() as stack:\n",
    "        inference_model = OpenPanopticInference(\n",
    "            model=model,\n",
    "            labels=demo_classes,\n",
    "            metadata=demo_metadata,\n",
    "            semantic_on=False,\n",
    "            instance_on=False,\n",
    "            panoptic_on=True,\n",
    "        )\n",
    "        stack.enter_context(inference_context(inference_model))\n",
    "        stack.enter_context(torch.no_grad())\n",
    "\n",
    "        demo = VisualizationDemo(inference_model, demo_metadata, aug)\n",
    "        _, visualized_output = demo.run_on_image(np.array(image))\n",
    "        return Image.fromarray(visualized_output.get_image())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let try a COCO image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open(requests.get(\"http://images.cocodataset.org/val2017/000000467848.jpg\", stream=True).raw)\n",
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = \"black pickup truck, pickup truck; blue sky, sky\"\n",
    "label_list = [\"COCO\", \"ADE\", \"LVIS\"]\n",
    "inference(input_image, vocab, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try non-COCO image,  [messy desk image](https://web.eecs.umich.edu/~fouhey/fun/desk/desk.jpg) (image credit [David Fouhey](https://web.eecs.umich.edu/~fouhey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open(requests.get(\"https://web.eecs.umich.edu/~fouhey/fun/desk/desk.jpg\", stream=True).raw)\n",
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = \"\"\n",
    "label_list = [\"COCO\", \"ADE\", \"LVIS\"]\n",
    "inference(input_image, vocab, label_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('odise')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "28ed3b998f5e77364eb443e6a07ff8c559c1427ace11964088e2f67d6ba1f461"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
